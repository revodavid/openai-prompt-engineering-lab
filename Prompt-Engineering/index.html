<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-Prompt-Engineering">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.0">
<title data-rh="true">Prompt Engineering | Explore Azure OpenAI Service</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://revodavid.github.io/openai-prompt-engineering-lab/Prompt-Engineering/"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Prompt Engineering | Explore Azure OpenAI Service"><meta data-rh="true" name="description" content="As we&#x27;ve seen, natural language Generative AI models can produce unexpected or unwanted responses to prompts. This can be caused by any number of factors, including:"><meta data-rh="true" property="og:description" content="As we&#x27;ve seen, natural language Generative AI models can produce unexpected or unwanted responses to prompts. This can be caused by any number of factors, including:"><link data-rh="true" rel="icon" href="/openai-prompt-engineering-lab/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://revodavid.github.io/openai-prompt-engineering-lab/Prompt-Engineering/"><link data-rh="true" rel="alternate" href="https://revodavid.github.io/openai-prompt-engineering-lab/Prompt-Engineering/" hreflang="en"><link data-rh="true" rel="alternate" href="https://revodavid.github.io/openai-prompt-engineering-lab/Prompt-Engineering/" hreflang="x-default"><script>!function(e,t,n,c,a,r,s){e[n]=e[n]||function(){(e[n].q=e[n].q||[]).push(arguments)},(r=t.createElement(c)).async=1,r.src="https://www.clarity.ms/tag/gxhc6407pe",(s=t.getElementsByTagName(c)[0]).parentNode.insertBefore(r,s)}(window,document,"clarity","script")</script><link rel="stylesheet" href="/openai-prompt-engineering-lab/assets/css/styles.13db0b21.css">
<link rel="preload" href="/openai-prompt-engineering-lab/assets/js/runtime~main.69045a75.js" as="script">
<link rel="preload" href="/openai-prompt-engineering-lab/assets/js/main.5d9c22fb.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><a class="navbar__brand" href="/openai-prompt-engineering-lab/"><div class="navbar__logo"><img src="/openai-prompt-engineering-lab/img/Azure-OpenAI-Services.svg" alt="My Site Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/openai-prompt-engineering-lab/img/Azure-OpenAI-Services.svg" alt="My Site Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Explore Azure OpenAI Service</b></a></div><div class="navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/openai-prompt-engineering-lab/">Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/openai-prompt-engineering-lab/Setup/">Workshop Setup in Azure</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/openai-prompt-engineering-lab/OpenAI-Setup/">Differences between OpenAI and Azure OpenAI Service</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/openai-prompt-engineering-lab/Explore-Models/">Explore OpenAI Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/openai-prompt-engineering-lab/Completions/">Understanding Completions</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/openai-prompt-engineering-lab/Tokens/">Understanding tokens</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/openai-prompt-engineering-lab/Applications/">Using Generative AI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/openai-prompt-engineering-lab/Conversations/">Conversations</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" href="/openai-prompt-engineering-lab/Prompt-Engineering/">Prompt Engineering</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/openai-prompt-engineering-lab/Using-the-API/">Using the API</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/openai-prompt-engineering-lab/Learnings-and-Resources/">Recap: What we&#x27;ve learned</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/openai-prompt-engineering-lab/Extra-Credit/">Other things to try</a></li></ul></nav></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/openai-prompt-engineering-lab/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Prompt Engineering</span><meta itemprop="position" content="1"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Prompt Engineering</h1><p>As we&#x27;ve seen, natural language Generative AI models can produce unexpected or unwanted responses to prompts. This can be caused by any number of factors, including:</p><ul><li>Insufficient information in the training data</li><li>Insufficient context in the prompt</li><li>Lack of capability of the model itself</li><li>Hostile intent by the user providing the prompt (&quot;jailbreaking&quot;)</li></ul><p>Prompt Engineering is the process of adding additional context to the prompt to provide &quot;grounding&quot; to the AI model and make it more likely to produce the desired response and less likely to produce undesirable outputs. For example, in a chatbot application, the system would inject additional instructions and data into the prompt before the user&#x27;s actual input, to provide context to the model. </p><p>In the prior Conversations section, the System message, the one-shot examples, and the conversation history all provide grounding to the model via the prompt. If you&#x27;re building an application that is based on a natural language generative AI model, your application will need to construct the prompt itself.</p><p>For more background, read <a href="https://learn.microsoft.com/en-us/azure/cognitive-services/openai/concepts/prompt-engineering" target="_blank" rel="noopener noreferrer">Introduction to prompt engineering on Microsoft Learn</a>. </p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="fine-tuning">Fine Tuning<a href="#fine-tuning" class="hash-link" aria-label="Direct link to Fine Tuning" title="Direct link to Fine Tuning">​</a></h2><p>Another technique you can use to improve the quality of responses is a process called &quot;<a href="https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/fine-tuning" target="_blank" rel="noopener noreferrer">fine-tuning</a>&quot;, which retrains the underlying model with example prompts and responses that you provide. We don&#x27;t cover fine-tuning in this workshop, primarily because prompt engineering generally produces better results, faster and more easily.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="prompt-engineering-techniques">Prompt Engineering Techniques<a href="#prompt-engineering-techniques" class="hash-link" aria-label="Direct link to Prompt Engineering Techniques" title="Direct link to Prompt Engineering Techniques">​</a></h2><p>Prompt Engineering is a complex and rapidly-evolving practice. The article <a href="https://learn.microsoft.com/en-us/azure/cognitive-services/openai/concepts/advanced-prompt-engineering" target="_blank" rel="noopener noreferrer">Prompt engineering techniques</a> on Microsoft Learn provides the latest guidance. </p><p>Choose one of the topics summarized below, and try out the examples provided in the page linked above. You can use either the Completions Playground or the Chat Playground for your tests. The Completions Playground is easiest to work with, but you will need to prepend the system message to the provided prompt in the User column. </p><ul><li><p><strong>System message</strong>: use the system message to prime the model with context, instructions, or other information relevant to the use case.</p></li><li><p><strong>Few-shot learning</strong>: adapt language models to new tasks by providing a set of training examples as part of the prompt.</p></li><li><p><strong>Non chat scenarios</strong>: use the Chat Completion API for non chat scenarios, such as sentiment analysis or entity extraction. </p></li><li><p><strong>Start with clear instructions</strong>: telling the model the task you want it to do at the beginning of the prompt, before sharing additional contextual information or examples, can help produce higher-quality outputs. </p></li><li><p><strong>Repeat instructions at the end</strong>: models can be susceptible to recency bias, which means that information at the end of the prompt might have more significant influence over the output than information at the beginning of the prompt. </p></li><li><p><strong>Prime the output</strong>: use a few words or phrases at the end of the prompt to obtain a model response that follows the desired form.</p></li><li><p><strong>Add clear syntax</strong>: use clear syntax for your prompt, such as punctuation, headings, and section markers, to communicate intent and make outputs easier to parse.</p></li><li><p><strong>Break the task down</strong>: large language models often perform better if the task is broken down into smaller steps. </p></li><li><p><strong>Use of affordances</strong>: you can use affordances external to the model, such as search, instead of relying on the model’s own parameters for information and answers. </p></li><li><p><strong>Chain of thought prompting</strong>: a variation on breaking down the task technique, where instead of splitting a task into smaller steps, you instruct the model response to proceed step-by-step and present all steps involved. </p></li><li><p><strong>Specifying the output structure</strong>: providing a model for the output structure can have significant impact on nature and quality of results. </p></li><li><p><strong>Temperature and Top_p parameters</strong>: changing the temperature or Top_probabilty parameters make the output more focused or more random. </p></li><li><p><strong>Provide grounding context</strong>: use an ancillary process to provide reliable data in the prompt for the model to draw responses from.</p></li></ul><p>Fun fact! The summarizations above were generated by Bing Chat (Creative Mode) from the contents of <a href="https://learn.microsoft.com/en-us/azure/cognitive-services/openai/concepts/advanced-prompt-engineering" target="_blank" rel="noopener noreferrer">this page</a> using the prompt: &quot;summarize this page section by section with a 1 sentence summary of each section&quot;, along with some light editing.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/revodavid/openai-prompt-engineering-lab/tree/main/docs/60-Prompt-Engineering.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/openai-prompt-engineering-lab/Conversations/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Conversations</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/openai-prompt-engineering-lab/Using-the-API/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Using the API</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#fine-tuning" class="table-of-contents__link toc-highlight">Fine Tuning</a></li><li><a href="#prompt-engineering-techniques" class="table-of-contents__link toc-highlight">Prompt Engineering Techniques</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 Explore the Azure OpenAI Service Workshop. Built with Docusaurus.</div></div></div></footer></div>
<script src="/openai-prompt-engineering-lab/assets/js/runtime~main.69045a75.js"></script>
<script src="/openai-prompt-engineering-lab/assets/js/main.5d9c22fb.js"></script>
</body>
</html>