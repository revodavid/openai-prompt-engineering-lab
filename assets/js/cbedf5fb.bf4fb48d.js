"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[321],{4137:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>h});var o=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,o)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,o,r=function(e,t){if(null==e)return{};var n,o,r={},a=Object.keys(e);for(o=0;o<a.length;o++)n=a[o],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(o=0;o<a.length;o++)n=a[o],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var p=o.createContext({}),s=function(e){var t=o.useContext(p),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},u=function(e){var t=s(e.components);return o.createElement(p.Provider,{value:t},e.children)},d="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},c=o.forwardRef((function(e,t){var n=e.components,r=e.mdxType,a=e.originalType,p=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),d=s(n),c=r,h=d["".concat(p,".").concat(c)]||d[c]||m[c]||a;return n?o.createElement(h,i(i({ref:t},u),{},{components:n})):o.createElement(h,i({ref:t},u))}));function h(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var a=n.length,i=new Array(a);i[0]=c;var l={};for(var p in t)hasOwnProperty.call(t,p)&&(l[p]=t[p]);l.originalType=e,l[d]="string"==typeof e?e:r,i[1]=l;for(var s=2;s<a;s++)i[s]=n[s];return o.createElement.apply(null,i)}return o.createElement.apply(null,n)}c.displayName="MDXCreateElement"},9560:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>i,default:()=>m,frontMatter:()=>a,metadata:()=>l,toc:()=>s});var o=n(7462),r=(n(7294),n(4137));const a={},i="Explore OpenAI Models",l={unversionedId:"Explore-Models",id:"Explore-Models",title:"Explore OpenAI Models",description:"Before you begin this section, navigate to your Azure OpenAI Studio homepage:",source:"@site/docs/10-Explore-Models.md",sourceDirName:".",slug:"/Explore-Models",permalink:"/openai-prompt-engineering-lab/Explore-Models",draft:!1,editUrl:"https://github.com/revodavid/openai-prompt-engineering-lab/tree/main/docs/10-Explore-Models.md",tags:[],version:"current",sidebarPosition:10,frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Differences between OpenAI and Azure OpenAI Service",permalink:"/openai-prompt-engineering-lab/OpenAI-Setup"},next:{title:"Understanding Completions",permalink:"/openai-prompt-engineering-lab/Completions"}},p={},s=[{value:"Completions vs Chat models",id:"completions-vs-chat-models",level:2},{value:"Your deployed models",id:"your-deployed-models",level:2},{value:"Which model should I use?",id:"which-model-should-i-use",level:2}],u={toc:s},d="wrapper";function m(e){let{components:t,...n}=e;return(0,r.kt)(d,(0,o.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"explore-openai-models"},"Explore OpenAI Models"),(0,r.kt)("p",null,"Before you begin this section, navigate to your Azure OpenAI Studio homepage:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"In the Azure Portal, click on the Azure OpenAI resource ",(0,r.kt)("inlineCode",{parentName:"li"},"openai-lab-build")),(0,r.kt)("li",{parentName:"ol"},'Click the "Explore" button to open the Azure OpenAI Studio')),(0,r.kt)("p",null,"Remember, you chose your own unique name to replace ",(0,r.kt)("inlineCode",{parentName:"p"},"openai-lab-build")," above. During this workshop you will often need to return to the home page of the Azure OpenAI Studio, so refer back to this section if you need a reminder of how to get there."),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"If you're using OpenAI, launch the OpenAI Playground. See ",(0,r.kt)("a",{parentName:"p",href:"/openai-prompt-engineering-lab/OpenAI-Setup"},"Differences between OpenAI and Azure OpenAI Service")," for details.")),(0,r.kt)("h2",{id:"completions-vs-chat-models"},"Completions vs Chat models"),(0,r.kt)("p",null,"TODO - also discuss Max Request limit."),(0,r.kt)("h2",{id:"your-deployed-models"},"Your deployed models"),(0,r.kt)("p",null,"Click on ",(0,r.kt)("strong",{parentName:"p"},"Deployments"),' in the "Management" section of the left pane. You have two models deployed:'),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"gpt-35-turbo-instruct"),": an instance of the OpenAI GPT-3.5 completions model"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"gpt-35-turbo"),": an instance of the OpenAI GPT-3.5 chat model ")),(0,r.kt)("p",null,"In this workshop, we will occasionally mention GPT-4, the latest model from OpenAI, but we will not deploy it."),(0,r.kt)("p",null,"You can find details about these models and other models available in Azure OpenAI Service at ",(0,r.kt)("a",{parentName:"p",href:"https://aka.ms/oai/models"},"https://aka.ms/oai/models"),". There you will learn that:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"The ",(0,r.kt)("inlineCode",{parentName:"li"},"gpt-35-turbo-instruct")," model is currently available in the US East and Sweden Central regions, has a Max Request limit of 4,097 tokens, and is based on training data up to September 2021."),(0,r.kt)("li",{parentName:"ul"},"The most recent (0613) version of ",(0,r.kt)("inlineCode",{parentName:"li"},"gpt-35-turbo")," is currently available in more than 10 regions, has a Max Request limit of 4,096 tokens, and is based on training data up to September 2021."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"gpt-4")," is only available by request in certain regions, has a Max Request limit of 8,192 tokens (or 32,768 tokens for the ",(0,r.kt)("inlineCode",{parentName:"li"},"gpt-4-32k")," variant), and is based on training data up to September 2021.")),(0,r.kt)("h2",{id:"which-model-should-i-use"},"Which model should I use?"),(0,r.kt)("p",null,"There are many considerations when choosing a model, including cost, availability, performance, and capability. But as a general guide, we recommend the following:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Start with ",(0,r.kt)("inlineCode",{parentName:"p"},"gpt-35-turbo"),'. This model is widely available, very economical, has good performance, and despite the fact that it is based on the "Chat" API it be used for a wide range of tasks beyond chat and conversation.')),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"For applications where text completion is the primary task, the simpler Completions API of ",(0,r.kt)("inlineCode",{parentName:"p"},"gpt-35-turbo-instruct")," may be attractive.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"If you need to generate more than 4,096 tokens, or need to support larger prompts, there is a variant of GPT-3.5 Turbo, ",(0,r.kt)("inlineCode",{parentName:"p"},"gpt-35-turbo-16k")," that supports a context window of 16,384 tokens. ")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"The most powerful model available today is ",(0,r.kt)("inlineCode",{parentName:"p"},"gpt-4")," (supporting a token window of 8192 tokens), or the 32k variant ",(0,r.kt)("inlineCode",{parentName:"p"},"gpt-4-32k")," which supports up to 31,278 tokens. While powerful, these models are more expensive and slower than GPT-3.5, have limited availability, and you must request access to use them with Azure OpenAI Service."))))}m.isMDXComponent=!0}}]);